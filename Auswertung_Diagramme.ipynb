{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# JSON-Datei laden\n",
    "dateipfad = 'jobs_titel_v13.json'\n",
    "df = pd.read_json(dateipfad)\n",
    "\n",
    "# Funktion, um die Top 8 Gruppen für ein bestimmtes Feld zu plotten\n",
    "def plot_top_groups(df, column, title):\n",
    "    plt.figure(figsize=(10, 6))  # Größere Plot-Größe\n",
    "    top_groups = df[column].value_counts().head(20)\n",
    "    top_groups.plot(kind='bar')\n",
    "    plt.title(title)\n",
    "    plt.ylabel('Anzahl')\n",
    "    plt.xticks(rotation=45)  # Drehung der X-Achsen-Beschriftungen\n",
    "    plt.tight_layout()  # Stellt sicher, dass alles gut passt\n",
    "    plt.show()\n",
    "\n",
    "# Plots für die gefragten Felder erstellen\n",
    "plot_top_groups(df, 'Tätigkeitsfeld', 'Top 6 Tätigkeitsfelder')\n",
    "plot_top_groups(df, 'Anstellungsdauer', 'Anstellungsdauer')\n",
    "plot_top_groups(df, 'Laufbahn / Entgeltgruppe', 'Laufbahnen / Entgeltgruppen')\n",
    "plot_top_groups(df, 'Arbeitszeit', 'Arbeitszeiten')\n",
    "plot_top_groups(df, 'Bundesland', 'Top 6  Bundesländer')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Laden der Daten\n",
    "file_path = 'jobs_titel_v13.json'\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Erstellen eines DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Erstellen der Barplots für jede Kennzahl\n",
    "fig, axes = plt.subplots(nrows=3, ncols=4, figsize=(20, 15))  # Anpassung auf 3x4 Subplots\n",
    "\n",
    "# Hilfsfunktion, um die Plots zu erstellen\n",
    "def create_barplot(ax, column, title, color):\n",
    "    counts = df[column].value_counts()\n",
    "    bars = ax.bar(counts.index, counts.values, color=color)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xticks([0, 1])\n",
    "    ax.set_xlabel('Wert')\n",
    "    ax.set_ylabel('Anzahl')\n",
    "    ax.set_ylim(0, 14000)\n",
    "    \n",
    "    # Hinzufügen von Text über den Balken\n",
    "    for bar in bars:\n",
    "        yval = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2, yval, int(yval), ha='center', va='bottom')\n",
    "\n",
    "# Plots für die neuen und alten Kennzahlen\n",
    "columns_titles_colors = [\n",
    "    ('hat_gm_titel', 'GM Titel', 'blue'),\n",
    "    ('hat_gm_text', 'GM Text', 'green'),\n",
    "    ('hat_mwd_titel', 'MWD Titel', 'red'),\n",
    "    ('hat_mwd_text', 'MWD Text', 'purple'),\n",
    "    ('hat_beid_titel', 'Beid Titel', 'cyan'),\n",
    "    ('hat_beid_text', 'Beid Text', 'magenta'),\n",
    "    ('hat_marker_titel', 'Marker Titel', 'orange'),\n",
    "    ('hat_marker_text', 'Marker Text', 'brown'),\n",
    "    ('hat_plural_titel', 'Plural Titel', 'yellow'),\n",
    "    ('hat_plural_text', 'Plural Text', 'lime'),\n",
    "    ('hat_feminin_titel', 'Feminin Titel', 'pink'),\n",
    "    ('hat_feminin_text', 'Feminin Text', 'gray')\n",
    "]\n",
    "\n",
    "for i, (column, title, color) in enumerate(columns_titles_colors):\n",
    "    ax = axes[i // 4, i % 4]\n",
    "    create_barplot(ax, column, title, color)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Reading the JSON file\n",
    "file_path = 'jobs_titel_v13.json'\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Extracting relevant data\n",
    "df = pd.DataFrame(data)\n",
    "kennzahl_gm = ['Kennzahl_GM_Titel', 'Kennzahl_GM_Text']\n",
    "kennzahl_agency = ['Kennzahl_Agency_Titel', 'Kennzahl_Agency_Text']\n",
    "\n",
    "# Filtering the DataFrame\n",
    "df_gm = df[kennzahl_gm]\n",
    "df_agency = df[kennzahl_agency]\n",
    "\n",
    "# Creating a density plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.kdeplot(data=df_gm, fill=True)\n",
    "plt.title('Dichtediagramm für Kennzahl_GM_Titel und Kennzahl_GM_Text')\n",
    "plt.xlabel('Werte')\n",
    "plt.ylabel('Dichte')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.kdeplot(data=df_agency, fill=True)\n",
    "plt.title('Dichtediagramm für Kennzahl_Agency_Titel und Kennzahl_Agency_Text')\n",
    "plt.xlabel('Werte')\n",
    "plt.ylabel('Dichte')\n",
    "plt.show()\n",
    "\n",
    "#boxplot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=df_gm)\n",
    "plt.title('Boxplot für Kennzahl_GM_Titel und Kennzahl_GM_Text')\n",
    "plt.ylabel('Werte')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=df_agency)\n",
    "plt.title('Boxplot für Kennzahl_Agency_Titel und Kennzahl_Agency_text')\n",
    "plt.ylabel('Werte')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the JSON data\n",
    "file_path = 'jobs_titel_v13.json'\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Convert the data to a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Create a scatter plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(df['Kennzahl_GM_Titel'], df['Kennzahl_GM_Text'], alpha=0.1)\n",
    "plt.xlabel('Kennzahl_GM_Titel')\n",
    "plt.ylabel('Kennzahl_GM_Text')\n",
    "plt.title('Scatter Plot of Kennzahl_GM_Titel vs Kennzahl_GM_Text')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the JSON data\n",
    "file_path = 'jobs_titel_v13.json'\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Convert the data to a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Create a scatter plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(df['Kennzahl_Agency_Titel'], df['Kennzahl_Agency_Text'], alpha=0.1)\n",
    "plt.xlabel('Kennzahl_Agency_Titel')\n",
    "plt.ylabel('Kennzahl_Agency_Text')\n",
    "plt.title('Scatter Plot of Kennzahl_Agency_Text vs Kennzahl_Agency_Titel')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Von allem Mittelwert (+sd), Anzahl Push1,2/Pull1,2 Wörter + Min, Max, Mittelwert (+ SD), 5 Häufigsten Wörter für Push/Pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Datensätze nach gr 0,5 filtern\n",
    "\n",
    "# Load the JSON file\n",
    "file_path = 'jobs_titel_v13.json'\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Filter out entries where 'Kennzahl_GM_text' is greater than 0.5\n",
    "filtered_data = [entry for entry in data if entry['Kennzahl_GM_Text'] > 0.5]\n",
    "\n",
    "# Path for the new JSON file\n",
    "new_file_path = 'jobs_titel_v13_gm_05.json'\n",
    "\n",
    "# Write the filtered data to a new JSON file\n",
    "with open(new_file_path, 'w', encoding='utf-8') as new_file:\n",
    "    json.dump(filtered_data, new_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "file_path = 'jobs_titel_v13.json'\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Filter out entries where 'Kennzahl_GM_text' is greater than 0.5\n",
    "filtered_data = [entry for entry in data if entry['Kennzahl_Agency_Text'] > 0.5]\n",
    "\n",
    "# Path for the new JSON file\n",
    "new_file_path = 'jobs_titel_v13_agency_05.json'\n",
    "\n",
    "# Write the filtered data to a new JSON file\n",
    "with open(new_file_path, 'w', encoding='utf-8') as new_file:\n",
    "    json.dump(filtered_data, new_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Laden der Excel-Datei\n",
    "file_path = 'final_test.xlsx'\n",
    "data = pd.read_excel(file_path)\n",
    "\n",
    "# Spalten, die visualisiert werden sollen\n",
    "columns = [\n",
    "    \"Mittelwert_Kennzahl_GM_Titel\",\n",
    "    \"Mittelwert_Kennzahl_GM_Text\",\n",
    "    \"Mittelwert_Kennzahl_Agency_Text\",\n",
    "    \"Mittelwert_Kennzahl_Agency_Titel\"\n",
    "]\n",
    "\n",
    "# Erstellen separater Diagramme für die Top 5 und Bottom 5, sortiert nach dem Merkmal, das geplottet wird\n",
    "fig, axes = plt.subplots(8, 1, figsize=(12, 48))\n",
    "\n",
    "for i, column in enumerate(columns):\n",
    "    # Sortieren und Auswählen der Top 5\n",
    "    top_5 = data.sort_values(by=column, ascending=False).head(5)\n",
    "    sns.barplot(x=column, y=\"kat_1\", data=top_5, ax=axes[2*i])\n",
    "    axes[2*i].set_title(f\"Top 5 - {column}\")\n",
    "    axes[2*i].set_xlabel('Mittelwert')\n",
    "    axes[2*i].set_ylabel('Kategorie')\n",
    "\n",
    "    # Sortieren und Auswählen der Bottom 5\n",
    "    bottom_5 = data.sort_values(by=column, ascending=True).head(5)\n",
    "    sns.barplot(x=column, y=\"kat_1\", data=bottom_5, ax=axes[2*i + 1])\n",
    "    axes[2*i + 1].set_title(f\"Bottom 5 - {column}\")\n",
    "    axes[2*i + 1].set_xlabel('Mittelwert')\n",
    "    axes[2*i + 1].set_ylabel('Kategorie')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Speichern der neuen Diagramme\n",
    "plot_file = 'mittelwert_kennzahlen_sorted_top_bottom_balkendiagramme.png'\n",
    "plt.savefig(plot_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mwd, top5 wörter, wie viele männlich/weiblich/neutral konnotiert, gesamt mittelwert + sd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ergebnis Excel erstellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from itertools import combinations\n",
    "from pathlib import Path\n",
    "\n",
    "# Laden der JSON-Daten\n",
    "file_path = Path('jobs_titel_nicht_agg.json')\n",
    "\n",
    "# Einlesen der JSON-Datei\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Umwandeln in ein DataFrame\n",
    "df = pd.json_normalize(data)\n",
    "\n",
    "# Berechnungsfunktion für Statistiken\n",
    "def calculate_statistics(df, category):\n",
    "    stats = df.groupby(category).agg(\n",
    "        Anzahl_Einträge=('titel', 'count'),\n",
    "        Mittelwert_Kennzahl_GM_Titel=('Kennzahl_GM_Titel', 'mean'),\n",
    "        StdAbw_Kennzahl_GM_Titel=('Kennzahl_GM_Titel', 'std'),\n",
    "        Mittelwert_Kennzahl_GM_Text=('Kennzahl_GM_Text', 'mean'),\n",
    "        StdAbw_Kennzahl_GM_Text=('Kennzahl_GM_Text', 'std'),\n",
    "        Mittelwert_Kennzahl_Agency_Text=('Kennzahl_Agency_Text', 'mean'),\n",
    "        StdAbw_Kennzahl_Agency_Text=('Kennzahl_Agency_Text', 'std'),\n",
    "        Mittelwert_Kennzahl_Agency_Titel=('Kennzahl_Agency_Titel', 'mean'),\n",
    "        StdAbw_Kennzahl_Agency_Titel=('Kennzahl_Agency_Titel', 'std'),\n",
    "        Mittelwert_Summe_Text_Agency=('anzahl_agency_text_analyse', 'mean'),\n",
    "        StdAbw_Summe_Text_Agency=('anzahl_agency_text_analyse', 'std'),\n",
    "        Mittelwert_Summe_Titel_Agency=('anzahl_agency_titel_analyse', 'mean'),\n",
    "        StdAbw_Summe_Titel_Agency=('anzahl_agency_titel_analyse', 'std'),\n",
    "        Mittelwert_Summe_Text_Communion=('anzahl_communion_text_analyse', 'mean'),\n",
    "        StdAbw_Summe_Text_Communion=('anzahl_communion_text_analyse', 'std'),\n",
    "        Mittelwert_Summe_Titel_Communion=('anzahl_communion_titel_analyse', 'mean'),\n",
    "        StdAbw_Summe_Titel_Communion=('anzahl_communion_titel_analyse', 'std'),\n",
    "        Mittelwert_Summe_Titel_GM=('anzahl_titel_gm', 'mean'),\n",
    "        Mittelwert_Summe_Titel_Feminin=('anzahl_titel_feminin', 'mean'),\n",
    "        Mittelwert_Summe_Text_GM=('anzahl_text_gm', 'mean'),\n",
    "        Mittelwert_Summe_Text_Feminin=('anzahl_text_feminin', 'mean'),\n",
    "        Mittelwert_hat_gm_titel=('hat_gm_titel', 'mean'),\n",
    "        Mittelwert_hat_gm_text=('hat_gm_text', 'mean'),\n",
    "        Mittelwert_hat_mwd_titel=('hat_mwd_titel', 'mean'),\n",
    "        Mittelwert_hat_mwd_text=('hat_mwd_text', 'mean'),\n",
    "        Mittelwert_hat_beid_titel=('hat_beid_titel', 'mean'),\n",
    "        Mittelwert_hat_beid_text=('hat_beid_text', 'mean'),\n",
    "        Mittelwert_hat_marker_titel=('hat_marker_titel', 'mean'),\n",
    "        Mittelwert_hat_marker_text=('hat_marker_text', 'mean'),\n",
    "        Mittelwert_hat_plural_titel=('hat_plural_titel', 'mean'),\n",
    "        Mittelwert_hat_plural_text=('hat_plural_text', 'mean'),\n",
    "        Mittelwert_hat_feminin_titel=('hat_feminin_titel', 'mean'),\n",
    "        Mittelwert_hat_feminin_text=('hat_feminin_text', 'mean')\n",
    "    )\n",
    "    return stats\n",
    "\n",
    "# Kategorien\n",
    "categories = ['Tätigkeitsfeld', 'Anstellungsdauer', 'Laufbahn / Entgeltgruppe', 'Bundesland', 'Arbeitszeit']\n",
    "\n",
    "# Statistiken für einzelne Kategorien\n",
    "individual_stats = {category.replace('/', ' und '): calculate_statistics(df, category) for category in categories}\n",
    "\n",
    "# Kombinationen von Kategorien\n",
    "category_combinations = list(combinations(categories, 2))\n",
    "\n",
    "# Statistiken für Kombinationen von Kategorien\n",
    "combined_stats = {f'{cat1.replace(\"/\", \" und \")} & {cat2.replace(\"/\", \" und \")}': calculate_statistics(df, [cat1, cat2]) \n",
    "                  for cat1, cat2 in category_combinations}\n",
    "\n",
    "# Erstellen einer Excel-Datei\n",
    "with pd.ExcelWriter('final_test_nicht_agg_eins.xlsx') as writer:\n",
    "    for key, value in individual_stats.items():\n",
    "        value.to_excel(writer, sheet_name=f'Individuell_{key}')\n",
    "\n",
    "    for key, value in combined_stats.items():\n",
    "        value.to_excel(writer, sheet_name=f'Kombiniert_{key}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scatter Plot auf neuer Datenbasis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the excel file\n",
    "file_path = 'final_test.xlsx'\n",
    "excel_data = pd.read_excel(file_path)\n",
    "\n",
    "# Define the function for creating scatter plots\n",
    "def create_scatter_plot(data, title, ax_labels, color1='blue', color2='red'):\n",
    "\n",
    "    x1 = data['Mittelwert_Summe_Text_Feminin']\n",
    "    x2 = data['Mittelwert_Summe_Text_Communion']\n",
    "    y1 = data['Mittelwert_Summe_Text_GM']\n",
    "    y2 = data['Mittelwert_Summe_Text_Agency']\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(x1, y1, color=color1, alpha=0.5, label='Feminin vs GM')\n",
    "    plt.scatter(x2, y2, color=color2, alpha=0.5, label='Communion vs Agency')\n",
    "\n",
    "    plt.axvline(x=x1.mean(), color=color1, linestyle='--', linewidth=1)\n",
    "    plt.axhline(y=y1.mean(), color=color1, linestyle='--', linewidth=1)\n",
    "    plt.axvline(x=x2.mean(), color=color2, linestyle='--', linewidth=1)\n",
    "    plt.axhline(y=y2.mean(), color=color2, linestyle='--', linewidth=1)\n",
    "\n",
    "    plt.xlabel(ax_labels[0])\n",
    "    plt.ylabel(ax_labels[1])\n",
    "    plt.xlim(0,30)\n",
    "    plt.ylim(0,30)\n",
    "    plt.grid(True)\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Filter data where 'Kat 2' is 0 for Plot 2\n",
    "filtered_data = excel_data[excel_data['kat_2'] == 0]\n",
    "\n",
    "# Create Scatter Plot 1\n",
    "create_scatter_plot(excel_data, 'Scatter Plot mit doppelter Gruppierung', ['Mittelwert Summe Text (Feminin/Communion)', 'Mittelwert Summe Text (GM/Agency)'])\n",
    "\n",
    "# Create Scatter Plot 2 with filtered data\n",
    "create_scatter_plot(filtered_data, 'Scatter Plot mit einfacher Gruppierung', ['Mittelwert Summe Text (Feminin/Communion)', 'Mittelwert Summe Text (GM/Agency)'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excel vorher auf Englisch stellen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'final_test.xlsx'\n",
    "data = pd.read_excel(file_path)\n",
    "\n",
    "# Definition der relevanten Spalten für die Bedingungen\n",
    "relevant_columns = [\n",
    "    'Mittelwert_Kennzahl_GM_Titel', \n",
    "    'Mittelwert_Kennzahl_GM_Text', \n",
    "    'Mittelwert_Kennzahl_Agency_Titel', \n",
    "    'Mittelwert_Kennzahl_Agency_Text'\n",
    "]\n",
    "\n",
    "# Ersetzen von Kommas durch Punkte und Umwandlung in numerische Werte\n",
    "for col in relevant_columns:\n",
    "    data[col] = data[col].astype(str).str.replace(',', '.').astype(float)\n",
    "\n",
    "# Definition der Bedingungen\n",
    "condition1 = data['Mittelwert_Kennzahl_GM_Titel'] > 0.5\n",
    "condition2 = data['Mittelwert_Kennzahl_GM_Text'] > 0.5\n",
    "condition3 = data['Mittelwert_Kennzahl_Agency_Titel'] > 0.5\n",
    "condition4 = data['Mittelwert_Kennzahl_Agency_Text'] > 0.5\n",
    "\n",
    "# Anwendung der Bedingungen und Zählen der Vorkommnisse in kat_1 und kat_2\n",
    "categories_count = {\n",
    "    'Bedingung 1 (GM Titel > 0,5)': data[condition1][['kat_1', 'kat_2']].apply(pd.value_counts).fillna(0).sum(axis=1),\n",
    "    'Bedingung 2 (GM Text > 0,5)': data[condition2][['kat_1', 'kat_2']].apply(pd.value_counts).fillna(0).sum(axis=1),\n",
    "    'Bedingung 3 (Agency Titel > 0,5)': data[condition3][['kat_1', 'kat_2']].apply(pd.value_counts).fillna(0).sum(axis=1),\n",
    "    'Bedingung 4 (Agency Text > 0,5)': data[condition4][['kat_1', 'kat_2']].apply(pd.value_counts).fillna(0).sum(axis=1)\n",
    "}\n",
    "\n",
    "# Erstellen eines DataFrames zur besseren Darstellung\n",
    "categories_count_df = pd.DataFrame(categories_count).fillna(0)\n",
    "\n",
    "# Anzeigen der Ergebnisse\n",
    "print(categories_count_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Aggregating counts for Text_Communion and Text_Agency\n",
    "communion_counts = Counter()\n",
    "agency_counts = Counter()\n",
    "\n",
    "for entry in data:\n",
    "    if \"Text_Communion\" in entry:\n",
    "        communion_counts.update(entry[\"Text_Communion\"])\n",
    "    if \"Text_Agency\" in entry:\n",
    "        agency_counts.update(entry[\"Text_Agency\"])\n",
    "\n",
    "# Generate word clouds based on the aggregated counts\n",
    "wordcloud_communion = WordCloud(width = 800, height = 400, background_color ='white').generate_from_frequencies(communion_counts)\n",
    "wordcloud_agency = WordCloud(width = 800, height = 400, background_color ='white').generate_from_frequencies(agency_counts)\n",
    "\n",
    "# Plotting the WordCloud images\n",
    "plt.figure(figsize=(15, 8))\n",
    "\n",
    "# Text_Communion WordCloud\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(wordcloud_communion, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.title('Text_Communion WordCloud')\n",
    "\n",
    "# Text_Agency WordCloud\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(wordcloud_agency, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.title('Text_Agency WordCloud')\n",
    "\n",
    "# Display the WordClouds\n",
    "plt.tight_layout(pad=0)\n",
    "plt.show()\n",
    "\n",
    "most_common_communion = communion_counts.most_common(10)\n",
    "most_common_agency = agency_counts.most_common(10)\n",
    "total_communion = sum(communion_counts.values())\n",
    "total_agency = sum(agency_counts.values())\n",
    "\n",
    "most_common_communion, most_common_agency,total_communion, total_agency\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "häufigste Wörter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "file_path = 'jobs_titel_v13.json'\n",
    "\n",
    "# Laden der Datei\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Zählen der Einträge für Text_Communion und Text_Agency\n",
    "text_communion_counts = {}\n",
    "text_agency_counts = {}\n",
    "\n",
    "for entry in data:\n",
    "    for word in entry.get('Text_Communion', {}):\n",
    "        text_communion_counts[word] = text_communion_counts.get(word, 0) + entry['Text_Communion'][word]\n",
    "\n",
    "    for word in entry.get('Text_Agency', {}):\n",
    "        text_agency_counts[word] = text_agency_counts.get(word, 0) + entry['Text_Agency'][word]\n",
    "\n",
    "# Sortieren und die 20 häufigsten Einträge zurückgeben\n",
    "top_20_text_communion = sorted(text_communion_counts.items(), key=lambda x: x[1], reverse=True)[:20]\n",
    "top_20_text_agency = sorted(text_agency_counts.items(), key=lambda x: x[1], reverse=True)[:20]\n",
    "\n",
    "# Umwandlung der Top-20-Listen in Wörterbücher für die Wordcloud-Erstellung\n",
    "text_communion_dict = dict(top_20_text_communion)\n",
    "text_agency_dict = dict(top_20_text_agency)\n",
    "print( top_20_text_agency)\n",
    "# Erstellung der Wordclouds\n",
    "wordcloud_communion = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(text_communion_dict)\n",
    "wordcloud_agency = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(text_agency_dict)\n",
    "\n",
    "# Zeichnen der Wordclouds\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.imshow(wordcloud_communion, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.title('Wordcloud für Text_Communion')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.imshow(wordcloud_agency, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.title('Wordcloud für Text_Agency')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_bezeichnung_counts = {}\n",
    "\n",
    "for entry in data:\n",
    "    for job_category, details in entry.get('job_bezeichnung', {}).items():\n",
    "        for i, gender_marker in enumerate(details['gender_marker_results']):\n",
    "            if gender_marker == 0 and details['beidnennung_results'][i] == 0:\n",
    "                job_title = details['job_title_results'][i]\n",
    "                job_bezeichnung_counts[job_title] = job_bezeichnung_counts.get(job_title, 0) + 1\n",
    "\n",
    "# Erstellen der Wordcloud für job_bezeichnung\n",
    "wordcloud_job_bezeichnung = WordCloud(width=800, height=400, background_color='white').generate_from_frequencies(job_bezeichnung_counts)\n",
    "\n",
    "# Zeichnen der Wordcloud\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.imshow(wordcloud_job_bezeichnung, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.title('Wordcloud GM')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Pfad zur JSON-Datei\n",
    "file_path = 'jobs_titel_v13.json'\n",
    "\n",
    "# JSON-Datei laden\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Filterkriterien anwenden\n",
    "filtered_data = [item for item in data \n",
    "                 if item.get('Kennzahl_GM_Text', 0) < 0.5 and \n",
    "                     #item.get('Kennzahl_GM_Titel', 0) >= 0.5) and \n",
    "                     item.get('mwd_count', 0) == 0 and \n",
    "                     (item.get('text_analyse', {}).get('text_feminin', 0)-item.get('text_analyse', {}).get('text_plural', 0)) > item.get('text_analyse', {}).get('text_gm', 0) and\n",
    "                     'assistenz' not in item.get('textfeld_femininum', {}) and \n",
    "                     'bürgermeisterin' not in item.get('textfeld_femininum', {}) and \n",
    "                     'fachbereichsleiterin' not in item.get('textfeld_femininum', {}) and \n",
    "                     'kauffrau' not in item.get('textfeld_femininum', {})]\n",
    "                    #'wart' not in item.get('job_title_counts', {}) and\n",
    "                    #'referent' not in item.get('job_title_counts', {}) and \n",
    "                    #'verantwortlicher' not in item.get('job_title_counts', {}) and \n",
    "                    #'ingenieur' not in item.get('job_title_counts', {}) and \n",
    "                    #'leiter' not in item.get('job_title_counts', {})]\n",
    "\n",
    "# Pfad für die neue Datei\n",
    "new_file_path = 'jobs_titel_nicht_agg_w.json'\n",
    "\n",
    "# Gefilterte Daten in eine neue Datei schreiben\n",
    "with open(new_file_path, 'w', encoding='utf-8') as new_file:\n",
    "    json.dump(filtered_data, new_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "new_file_path\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
